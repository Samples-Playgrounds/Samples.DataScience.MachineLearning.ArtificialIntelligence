# Thinking

# 65 GB
ollama pull gpt-oss:120b
# 43 GB
ollama pull deepseek-r1:70b
# 20 GB
ollama pull qwen3:32b
ollama pull llama3.1:70b

*   gpt-oss

    OpenAI’s open-weight models designed for powerful reasoning, agentic tasks, and versatile developer use cases.
        20b
        120b

        1.2M

*   deepseek-r1

    DeepSeek-R1 is a family of open reasoning models with performance approaching that of leading models, such as O3 and Gemini 2.5 Pro.

    1.5b
    7b
    8b
    14b
    32b
    70b
    671b

    58.1M
    Pulls


*   qwen3

    Qwen3 is the latest generation of large language models in Qwen series, offering a comprehensive suite of dense and mixture-of-experts (MoE) models.

0.6b
1.7b
4b
8b
14b
30b
32b
235b

5.9M
 Pulls

magistral
Magistral is a small, efficient reasoning model with 24B parameters.

24b
290.7K
 Pulls


https://www.reddit.com/r/ollama/comments/1kzp7cz/thinking_models/

“thinking” output is the output of each encoder/decoder output/interaction, working out the importance and context of individual words in a sentence or prompt. This was the link I read, for anyone else curious: 

https://www.truefoundry.com/blog/transformer-architecture

https://ollama.com/search?c=thinking

